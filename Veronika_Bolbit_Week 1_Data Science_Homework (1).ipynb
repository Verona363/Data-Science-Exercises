{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Data Science 2025\n",
    "\n",
    "# Week 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1 | Matrix warm-up\n",
    "<span style=\"background-color: #ccfff2\"> *Note: You can find tutorials for NumPy and Pandas under 'Useful tutorials' in the course material.*</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most useful properties of any scientific programming language (Python with NumPy, R, Julia, etc) is that they allow us to work with matrices efficiently. Let's learn more about these features!\n",
    "\n",
    "### 1.1 Basics\n",
    "\n",
    "1. Let's start by creating two arrays <span style=\"background-color: #ccfff2\"> A</span> and <span style=\"background-color: #ccfff2\"> B</span> which each have the integers <span style=\"background-color: #ccfff2\"> 0, 1, 2, ..., 1e7-1</span>. Use the normal arrays or lists of the programming language you are using, e.g. *list* or *[ ]* or *numpy.array()* in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "A=np.arange(0,int(1e7))\n",
    "B=np.arange(0,int(1e7))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Create a function that uses a <span style=\"background-color: #ccfff2\"> for loop</span> or equivalent to return a new array <span style=\"background-color: #ccfff2\"> C</span>, which contains the <span style=\"background-color: #ccfff2\"> element-wise sum of *A* and *B*</span>, e.g. C should contain the integers <span style=\"background-color: #ccfff2\"> 0, 2, 4, etc</span>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_with_for(A,B):\n",
    "    C = []\n",
    "    for i in range (len(A)):\n",
    "        C.append(int(A[i]+B[i]))\n",
    "    return C\n",
    "print(add_with_for(A,B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Next, let's create another function that uses NumPy (or equivalent) to do the same. To try it out, allocate two arrays (e.g. using <span style=\"background-color: #ccfff2\"> np.array</span> in NumPy) and add the arrays together using your function. Don't use loops, instead, find out how to add the two arrays directly. What do you notice in comparison to the previous function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_with_for(A, B):\n",
    "    return (A+B)\n",
    "\n",
    "print(add_with_for(A,B))\n",
    "#I notice that if I use NumPy and call function, e.g (print(add_with_for(A, B))) it's much faster with Numpy and more efficient for large arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Array manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"background-color: #ccfff2\"> *Note: for the following exercises, only use NumPy or equivalent functions. Don't use any loops.* </span>\n",
    "1. Create the following array:\n",
    "\n",
    "*[hint: <span style=\"background-color: #ccfff2\"> np.reshape</span>]*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# array([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
    "#        [10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n",
    "#        [20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n",
    "#        [30, 31, 32, 33, 34, 35, 36, 37, 38, 39],\n",
    "#        [40, 41, 42, 43, 44, 45, 46, 47, 48, 49],\n",
    "#        [50, 51, 52, 53, 54, 55, 56, 57, 58, 59],\n",
    "#        [60, 61, 62, 63, 64, 65, 66, 67, 68, 69],\n",
    "#        [70, 71, 72, 73, 74, 75, 76, 77, 78, 79],\n",
    "#        [80, 81, 82, 83, 84, 85, 86, 87, 88, 89],\n",
    "#        [90, 91, 92, 93, 94, 95, 96, 97, 98, 99]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2  3  4  5  6  7  8  9]\n",
      " [10 11 12 13 14 15 16 17 18 19]\n",
      " [20 21 22 23 24 25 26 27 28 29]\n",
      " [30 31 32 33 34 35 36 37 38 39]\n",
      " [40 41 42 43 44 45 46 47 48 49]\n",
      " [50 51 52 53 54 55 56 57 58 59]\n",
      " [60 61 62 63 64 65 66 67 68 69]\n",
      " [70 71 72 73 74 75 76 77 78 79]\n",
      " [80 81 82 83 84 85 86 87 88 89]\n",
      " [90 91 92 93 94 95 96 97 98 99]]\n"
     ]
    }
   ],
   "source": [
    "a=np.arange(0, 100)\n",
    "b=a.reshape(10, 10)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Create the following array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# array([[0., 1., 0., 1., 0., 1., 0., 1., 0., 1.],\n",
    "#        [0., 1., 0., 1., 0., 1., 0., 1., 0., 1.],\n",
    "#        [0., 1., 0., 1., 0., 1., 0., 1., 0., 1.],\n",
    "#        [0., 1., 0., 1., 0., 1., 0., 1., 0., 1.],\n",
    "#        [0., 1., 0., 1., 0., 1., 0., 1., 0., 1.],\n",
    "#        [0., 1., 0., 1., 0., 1., 0., 1., 0., 1.],\n",
    "#        [0., 1., 0., 1., 0., 1., 0., 1., 0., 1.],\n",
    "#        [0., 1., 0., 1., 0., 1., 0., 1., 0., 1.],\n",
    "#        [0., 1., 0., 1., 0., 1., 0., 1., 0., 1.],\n",
    "#        [0., 1., 0., 1., 0., 1., 0., 1., 0., 1.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. 1. 0. 1. 0. 1. 0. 1.]\n",
      " [0. 1. 0. 1. 0. 1. 0. 1. 0. 1.]\n",
      " [0. 1. 0. 1. 0. 1. 0. 1. 0. 1.]\n",
      " [0. 1. 0. 1. 0. 1. 0. 1. 0. 1.]\n",
      " [0. 1. 0. 1. 0. 1. 0. 1. 0. 1.]\n",
      " [0. 1. 0. 1. 0. 1. 0. 1. 0. 1.]\n",
      " [0. 1. 0. 1. 0. 1. 0. 1. 0. 1.]\n",
      " [0. 1. 0. 1. 0. 1. 0. 1. 0. 1.]\n",
      " [0. 1. 0. 1. 0. 1. 0. 1. 0. 1.]\n",
      " [0. 1. 0. 1. 0. 1. 0. 1. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "a=np.zeros((10, 10)) #datatype is float if i do a=np.zeros((10, 10), dtype=int)\n",
    "a[:, 1::2]=1\n",
    "print(a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Create the following array (D):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# array([[0., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
    "#        [1., 0., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
    "#        [1., 1., 0., 1., 1., 1., 1., 1., 1., 1.],\n",
    "#        [1., 1., 1., 0., 1., 1., 1., 1., 1., 1.],\n",
    "#        [1., 1., 1., 1., 0., 1., 1., 1., 1., 1.],\n",
    "#        [1., 1., 1., 1., 1., 0., 1., 1., 1., 1.],\n",
    "#        [1., 1., 1., 1., 1., 1., 0., 1., 1., 1.],\n",
    "#        [1., 1., 1., 1., 1., 1., 1., 0., 1., 1.],\n",
    "#        [1., 1., 1., 1., 1., 1., 1., 1., 0., 1.],\n",
    "#        [1., 1., 1., 1., 1., 1., 1., 1., 1., 0.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 0. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 0. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 0. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 0. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 0. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "D=np.ones((10,10))\n",
    "b=np.array([0,1,2,3,4,5,6,7,8,9])\n",
    "D[np.arange(10), b]=0\n",
    "print(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Create the following array (E):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
    "#        [1., 1., 1., 1., 1., 1., 1., 1., 0., 1.],\n",
    "#        [1., 1., 1., 1., 1., 1., 1., 0., 1., 1.],\n",
    "#        [1., 1., 1., 1., 1., 1., 0., 1., 1., 1.],\n",
    "#        [1., 1., 1., 1., 1., 0., 1., 1., 1., 1.],\n",
    "#        [1., 1., 1., 1., 0., 1., 1., 1., 1., 1.],\n",
    "#        [1., 1., 1., 0., 1., 1., 1., 1., 1., 1.],\n",
    "#        [1., 1., 0., 1., 1., 1., 1., 1., 1., 1.],\n",
    "#        [1., 0., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
    "#        [0., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9 8 7 6 5 4 3 2 1 0]\n",
      "[[1. 1. 1. 1. 1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 0. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 0. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 0. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 0. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 0. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "E=np.ones((10,10))\n",
    "b=np.arange(9,-1, -1) #we need -1 cuz default is 1\n",
    "E[np.arange(10), b]=0\n",
    "print(b)\n",
    "print(E)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Call the last two matrices <span style=\"background-color: #ccfff2\">D</span> and <span style=\"background-color: #ccfff2\">E</span>, respectively. Show that the determinant of their product (matrix multiplication) is the same as the product of their determinants. That is calculate both <span style=\"background-color: #ccfff2\">det(DE)</span> and <span style=\"background-color: #ccfff2\">det(D) * det(E)</span>, and show that they are the same. Is it a coincidence? (I think not) The product of the determinants (or the determinant of the product) should be -81."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-81.0\n",
      "-80.99999999999996\n",
      "Are they equal? True\n"
     ]
    }
   ],
   "source": [
    "DE=np.dot(D, E)\n",
    "det_E=np.linalg.det(E)\n",
    "det_D=np.linalg.det(D)\n",
    "result_det=det_E*det_D\n",
    "result_det_DE=np.linalg.det(DE)\n",
    "print(result_det)\n",
    "print(result_det_DE)\n",
    "\n",
    "print(\"Are they equal?\", np.isclose(result_det_DE, result_det))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#It is not a coincidence, since there is a theorem in linear algebra that states that the product of the determinants is equal to the determinant of the product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Slicing\n",
    "\n",
    "Array slicing is a powerful way to extract data from an array. Let's practice array slicing with the following exercises!\n",
    "\n",
    "1. Load the [California housing dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html). The data should be a matrix of shape <span style=\"background-color: #ccfff2\">(20640, 8)</span>, that is 20640 rows and 8 columns. Use the <span style=\"background-color: #ccfff2\">.shape</span> attribute of NumPy arrays to verify this. Here's a [description of the fields](https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20640, 8)\n",
      "(20640,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "housing = fetch_california_housing(as_frame=False)  # downloads the dataset\n",
    "X = housing.data\n",
    "y = housing.target\n",
    "\n",
    "print(X.shape)  # (20640, 8)\n",
    "print(y.shape)  # (20640,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Select rows where the average number of bedrooms <span style=\"background-color: #ccfff2\">(AveBedrms)</span> is higher than 2. The first few row indices should be <span style=\"background-color: #ccfff2\">710,  1023,  1024, ...</span> (zero-indexed). Count these houses - how many rows are selected? *[hint: <span style=\"background-color: #ccfff2\">np.where</span>]*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few indices [ 710 1023 1024 1030 1102 1233]\n",
      "Number of houses/rows 235\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "housing = fetch_california_housing(as_frame=True)\n",
    "df = housing.frame  \n",
    "indicies=np.where(df[\"AveBedrms\"]>2)[0]\n",
    "\n",
    "print(f\"First few indices {indicies[0:6]}\")\n",
    "print(f\"Number of houses/rows {len(indicies)}\")\n",
    "#Since np.where returns a tuple, [0] extracts the actual array of indices.\n",
    "#So now indices is an array like [710, 1023, 1024, ...]  \n",
    "# which are the rows where the average number of bedrooms per household is greater than 2.\n",
    "#np.where(df[\"AveBedrms\"] > 2) returns (array([1, 3, 4]),)\n",
    "#That’s why we add [0] to extract the actual array.----[1 3 4]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Select the rows where the median house age (i.e. median in each block group) <span style=\"background-color: #ccfff2\">(HouseAge)</span> is between 1 and 3 years (inclusive). There should be **124** of these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows where median house age is between 1 and 3 is 124\n"
     ]
    }
   ],
   "source": [
    "median_age_rows=np.where((df[\"HouseAge\"]>=1) & (df[\"HouseAge\"]<=3))[0]\n",
    "print(f\"Rows where median house age is between 1 and 3 is {len(median_age_rows)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Find the mean of the block group population <span style=\"background-color: #ccfff2\">(Population)</span> for homes whose median value is more than 25000 USD (the target variable). It should be around **1425.68**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean block group population for homes > $25,000: 1425.68\n"
     ]
    }
   ],
   "source": [
    "rows_highmedian_value=np.where(df[\"MedHouseVal\"]>0.25)[0] #returns array of indicies\n",
    "population_values=df[\"Population\"].iloc[rows_highmedian_value]\n",
    "mean_population=np.mean(population_values)\n",
    "print(f\"Mean block group population for homes > $25,000: {mean_population:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 | Working with text data\n",
    "\n",
    "Next, let's look into some text data. We will be looking into Amazon reviews, and the necessary steps to transform a raw dataset into a format more suitable for prediction tasks.\n",
    "\n",
    "1. Download the automotive 5-core dataset from [here](https://jmcauley.ucsd.edu/data/amazon_v2/categoryFilesSmall/Automotive_5.json.gz). Next, you can extract the data in <span style=\"background-color: #ccfff2\">JSON</span> format. You can also download one of the bigger ones, if you are feeling ambitious. Open the JSON file. Access the <span style=\"background-color: #ccfff2\">reviewText</span> field, which contains the unstructured review text written by the user.\n",
    "\n",
    "For instance, the first review reads as follows: \n",
    "\n",
    "*'After I wrote the below review, the manufacturer contacted me and explained how to use this.  Instead of the (current) picture on Amazon where the phone is placed vertically, you actually use the stand with the phone placed horizontally. [...]'*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "import re\n",
    "\n",
    "file_path = 'Automotive_5.json.gz'  \n",
    "\n",
    "reviews = []\n",
    "with gzip.open(file_path, 'rt', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        reviews.append(json.loads(line))\n",
    "\n",
    "print(f\"Total reviews loaded: {len(reviews)}\")\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()                      \n",
    "    text = re.sub(r'[^a-z0-9\\s]', '', text) \n",
    "    text = re.sub(r'\\s+', ' ', text)       \n",
    "    return text.strip()\n",
    "\n",
    "cleaned_texts = [clean_text(review['reviewText']) for review in reviews]\n",
    "\n",
    "ratings = [review['overall'] for review in reviews]\n",
    "\n",
    "for i in range(3):\n",
    "    print(f\"Review {i+1}: {cleaned_texts[i]}\")\n",
    "    print(f\"Rating {i+1}: {ratings[i]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Next, let's follow some steps to normalize the text data.\n",
    "\n",
    "When dealing with natural language, it is important to notice that while, for example, the words \"Copper\" and \"copper\" are represented by two different strings, they have the same meaning. When applying statistical methods on this data, it is useful to ensure that words with the same meaning are represented by the same string.\n",
    "\n",
    "* <span style=\"background-color: #ccfff2\">Downcasing</span>: Let's first downcase the contents of the <span style=\"background-color: #ccfff2\">reviewText</span> field.\n",
    "\n",
    "Now the first review should be:\n",
    "\n",
    "*'after i wrote the below review, the manufacturer contacted me and explained how to use this.  instead of the (current) picture on amazon where the phone is placed vertically, you actually use the stand with the phone placed horizontally.'*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "downcased_texts = [review['reviewText'].lower() for review in reviews]\n",
    "\n",
    "print(downcased_texts[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Let's continue with punctuation and stop word removal. Stop words are words like \"and\", \"the\", etc. They are usually very common words that have little to do with the actual content matter. There's plenty openly available lists of stop words for almost any (natural) language.\n",
    "\n",
    "* <span style=\"background-color: #ccfff2\">Punctuation and stop-word removal</span>: Let's now remove all punctuation, as well as the stop words. You can find a stop word list for English, e.g. [here](https://gist.github.com/xldrkp/4a3b1a33f10d37bedbe0068f2b4482e8#file-stopwords-en-txt).*(use the link to download a txt of english stopwords)* Save the stopwords in the file as \"stopwords-en.txt\".\n",
    "\n",
    "First review at this point reads as: \n",
    "\n",
    "*'wrote review manufacturer contacted explained current picture amazon phone vertically stand phone horizontally'*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('stopwords-en.txt', 'r') as f:\n",
    "    stopwords = set(f.read().splitlines())\n",
    "\n",
    "print(f\"Total stopwords loaded: {len(stopwords)}\")\n",
    "\n",
    "import re\n",
    "\n",
    "def clean_text_remove_stopwords(text, stopwords):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z0-9\\s]', '', text)\n",
    "    words = text.split()\n",
    "    words = [word for word in words if word not in stopwords]\n",
    "    return ' '.join(words)\n",
    "\n",
    "normalized_texts = [clean_text_remove_stopwords(review['reviewText'], stopwords) for review in reviews]\n",
    "\n",
    "print(normalized_texts[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Let's continue with stemming. For example, while the words \"swims\" and \"swim\" are different strings, they both refer to swimming. [Stemming](https://en.wikipedia.org/wiki/Stemming) refers to the process of mapping words from their inflected form to their base form, for instance: swims -> swim.\n",
    "\n",
    "* <span style=\"background-color: #ccfff2\">Stemming</span>: Apply a stemmer on the paragraphs, so that inflected forms are mapped to the base form. For example, for Python the popular natural language toolkit [nltk](http://www.nltk.org/howto/stem.html) has an easy to use stemmer. In case you are using R, you can try the [Snowball stemmer](https://www.rdocumentation.org/packages/corpus/versions/0.10.2/topics/stem_snowball). You can find out how to install nltk from [here](https://www.nltk.org/install.html). It will take a while to run! So, grab a coffee and wait :D\n",
    "\n",
    "Finally, after stemming: \n",
    "\n",
    "*'wrote review manufactur contact explain current pictur amazon phone vertic stand phone horizont'*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import \n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def stem_text(text):\n",
    "    words = text.split()\n",
    "    stemmed_words = [stemmer.stem(word) for word in words]\n",
    "    return ' '.join(stemmed_words)\n",
    "\n",
    "stemmed_texts = [stem_text(text) for text in normalized_texts]\n",
    "\n",
    "print(stemmed_texts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Finally, filter the data by selecting reviews where the field <span style=\"background-color: #ccfff2\">overall</span> is 4 or 5, and store the review texts in a file named <span style=\"background-color: #ccfff2\">pos.txt</span>. Similarly, select reviews with rating 1 or 2 and store them in a file named <span style=\"background-color: #ccfff2\">neg.txt</span>. Ignore the reviews with overall rating 3. Each line in the two files should contain exactly one preprocessed review text without the rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_reviews = [stemmed_texts[i] for i, review in enumerate(reviews) if review['overall'] in [4, 5]]\n",
    "neg_reviews = [stemmed_texts[i] for i, review in enumerate(reviews) if review['overall'] in [1, 2]]\n",
    "\n",
    "with open('pos.txt', 'w', encoding='utf-8') as f:\n",
    "    for review in pos_reviews:\n",
    "        f.write(review + '\\n')\n",
    "\n",
    "with open('neg.txt', 'w', encoding='utf-8') as f:\n",
    "    for review in neg_reviews:\n",
    "        f.write(review + '\\n')\n",
    "\n",
    "print(f\"Positive reviews saved: {len(pos_reviews)}\")\n",
    "print(f\"Negative reviews saved: {len(neg_reviews)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3 | SQL basics\n",
    "\n",
    "Next, let's take a refresher on the basics of SQL. In this exercise, you will be working on the simplified Northwind 2000 SQLite database. You can download the database from Kaggle [here](https://courses.mooc.fi/api/v0/files/course/f92ffc32-2dd4-421d-87f3-c48800422cc5/files/VEKX2bxGCDGyojG902gmYZTXCnrAQw.zip).\n",
    "\n",
    "To test your SQL queries and complete the exercise, you can download and install SQLite if you don't yet have it installed.\n",
    "\n",
    "Please write SQL queries for the tasks on the simplified Northwind 2000 SQLite database.\n",
    "\n",
    "1. List the first name, last name, and hire date of all employees hired after January 1st, 1994.\n",
    "\n",
    "2. Count how many orders each customer has placed.\n",
    "\n",
    "3. Find the names of all customers who have ordered the product \"Chai\".\n",
    "\n",
    "4. Find all orders that have been placed but not yet shipped.\n",
    "\n",
    "5. Find the customer who has placed the most orders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remember to submit your solutions. You can return this Jupyter notebook (.ipynb) or .py, .R, etc depending on your programming preferences. Remember to also submit your SQL queries. No need to submit the text files for the programming exercises.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "DatabaseError",
     "evalue": "Execution failed on sql '\nSELECT CustomerID, COUNT(*) AS OrderCount\nFROM Orders\nGROUP BY CustomerID;\n': no such table: Orders",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOperationalError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HP LAPTOP 15S-FQ2023\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\sql.py:2664\u001b[39m, in \u001b[36mSQLiteDatabase.execute\u001b[39m\u001b[34m(self, sql, params)\u001b[39m\n\u001b[32m   2663\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2664\u001b[39m     \u001b[43mcur\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2665\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cur\n",
      "\u001b[31mOperationalError\u001b[39m: no such table: Orders",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mDatabaseError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      4\u001b[39m conn = sqlite3.connect(\u001b[33m\"\u001b[39m\u001b[33mNorthwind.sqlite\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m query = \u001b[33m\"\"\"\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[33mSELECT CustomerID, COUNT(*) AS OrderCount\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[33mFROM Orders\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[33mGROUP BY CustomerID;\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[33m\"\"\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m df_orders = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_sql_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m df_orders.head()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HP LAPTOP 15S-FQ2023\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\sql.py:528\u001b[39m, in \u001b[36mread_sql_query\u001b[39m\u001b[34m(sql, con, index_col, coerce_float, params, parse_dates, chunksize, dtype, dtype_backend)\u001b[39m\n\u001b[32m    525\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m dtype_backend \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib.no_default\n\u001b[32m    527\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m pandasSQL_builder(con) \u001b[38;5;28;01mas\u001b[39;00m pandas_sql:\n\u001b[32m--> \u001b[39m\u001b[32m528\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpandas_sql\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    529\u001b[39m \u001b[43m        \u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    530\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    531\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    532\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcoerce_float\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcoerce_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    533\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    534\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    536\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    537\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HP LAPTOP 15S-FQ2023\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\sql.py:2728\u001b[39m, in \u001b[36mSQLiteDatabase.read_query\u001b[39m\u001b[34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize, dtype, dtype_backend)\u001b[39m\n\u001b[32m   2717\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mread_query\u001b[39m(\n\u001b[32m   2718\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   2719\u001b[39m     sql,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2726\u001b[39m     dtype_backend: DtypeBackend | Literal[\u001b[33m\"\u001b[39m\u001b[33mnumpy\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mnumpy\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   2727\u001b[39m ) -> DataFrame | Iterator[DataFrame]:\n\u001b[32m-> \u001b[39m\u001b[32m2728\u001b[39m     cursor = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2729\u001b[39m     columns = [col_desc[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m col_desc \u001b[38;5;129;01min\u001b[39;00m cursor.description]\n\u001b[32m   2731\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HP LAPTOP 15S-FQ2023\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\sql.py:2676\u001b[39m, in \u001b[36mSQLiteDatabase.execute\u001b[39m\u001b[34m(self, sql, params)\u001b[39m\n\u001b[32m   2673\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01minner_exc\u001b[39;00m\n\u001b[32m   2675\u001b[39m ex = DatabaseError(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExecution failed on sql \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msql\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m2676\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
      "\u001b[31mDatabaseError\u001b[39m: Execution failed on sql '\nSELECT CustomerID, COUNT(*) AS OrderCount\nFROM Orders\nGROUP BY CustomerID;\n': no such table: Orders"
     ]
    }
   ],
   "source": [
    "#1 st query\n",
    "SELECT FirstName, LastName, HireDate\n",
    "FROM Employees\n",
    "WHERE HireDate > '1994-01-01';\n",
    "\n",
    "#2nd query\n",
    "SELECT CustomerID, COUNT(*) AS OrderCount\n",
    "FROM Orders\n",
    "GROUP BY CustomerID;\n",
    "#3rd query\n",
    "SELECT DISTINCT c.CompanyName\n",
    "FROM Customers c\n",
    "JOIN Orders o ON c.CustomerID = o.CustomerID\n",
    "JOIN OrderDetails od ON o.OrderID = od.OrderID\n",
    "JOIN Products p ON od.ProductID = p.ProductID\n",
    "WHERE p.ProductName = 'Chai';\n",
    "#4th query\n",
    "SELECT *\n",
    "FROM Orders\n",
    "WHERE ShippedDate IS NULL;\n",
    "#5th query\n",
    "SELECT CustomerID, COUNT(*) AS OrderCount\n",
    "FROM Orders\n",
    "GROUP BY CustomerID\n",
    "ORDER BY OrderCount DESC\n",
    "LIMIT 1;\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
